# ðŸ§  Machine Learning Assignments

This repository contains my solutions to two major Machine Learning assignments, implemented in Python using Jupyter notebooks.  
Each notebook demonstrates full data science workflows including **data exploration**, **feature engineering**, **model training**, **evaluation**, and **visualization**.

---

## ðŸ“‚ Contents

### **1. Assignment 2 â€“ Spotify & YouTube Song Classification**
**Notebook:** `ML_HW2`  

#### **Objective**
Predict whether a song is published as a **single** or as part of an **album**, using a dataset with over 20,000 songs and their features.

#### **Key Workflows**
- **Data Exploration & Visualization:**  
  - At least 5 meaningful visualizations highlighting feature distributions and correlations.
- **Data Preprocessing:**  
  - Feature engineering including album-level statistics, artist metrics, and new derived features.
  - Handling imbalanced labels.
- **Classification:**  
  - Trained and tuned 3 ML models (e.g., Logistic Regression, Random Forest, Gradient Boosting).  
  - Compared results using accuracy, precision, recall, and F1-score.
- **Clustering:**  
  - Applied 2 clustering algorithms to group songs.  
  - Evaluated clusters and analyzed feature contributions.
- **Bonus:** Feature importance analysis & additional artist-level insights.

---

### **2. Assignment 3 â€“ Forest Cover, MNIST, and Bonus Synthetic Data**
**Notebook:** `ML_HW3`  

#### **Objective**
Work on three datasets (Forest Cover, MNIST digits, and high-dimensional synthetic data) to apply classification, clustering, PCA, and dimensionality reduction techniques.

#### **Key Workflows**
- **Part 1 â€“ Forest Cover Type**  
  - Data exploration with 5 insightful visualizations.  
  - Feature engineering & preprocessing.  
  - Classification using 3 ML models with parameter tuning.  
  - Clustering with 2 algorithms and evaluation of cluster quality.  
  - PCA for dimensionality reduction, followed by re-evaluation of models.

- **Part 2 â€“ MNIST Even Digits**  
  - Visualization of digits & pixel heatmaps.  
  - Classification with 2 tuned models, logging training and prediction times.  
  - PCA & feature importance analysis to identify the most and least relevant pixels.  
  - Feature selection based on explained variance and comparison across multiple runs.  
  - t-SNE visualization for cluster separation.

- **Part 3 â€“ Bonus Synthetic Data**  
  - Model training on high-dimensional data.  
  - Feature importance analysis and dropping uninformative features.  
  - Outlier detection using multiple methods and evaluation via recall and accuracy.

---
